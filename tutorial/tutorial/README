Based on the Scrapy lib
get web data of dazongdianping（大众点评）,soufang（搜房） and lianjia（链家） data.
Other users can modify the content of python file to satisfy owner application

网络爬虫，用于爬取大众点评，搜房，链家上的数据

if users want export data as csv format , input : scrapy crawl soufangV2_spider -t csv -o sfqd20180224.csv --loglevel=INFO

recommend is export the data into database (MySQL).details please reference web


Anyother questions pleasure connect the author: hardysong110@163.com

INIT只能有一个。scrapy系统已经内置了程序文件如何作用，不可以通过更改文件名的方式切换init

遗留问题:
	1.在parse中，再调用request，程序运行几次后，卡住无法运行。猜想可能是parse本身是子线程，在子线程中又调用其他程序，当线程多了之后程序拥塞
	2.middleware不能正常使用

问题解决：
	1.将程序的start_url设置成一个网址，然后通过nextpage和Request结合的方式，成功完成数据抓取，验证。
		通过这样的方式，确实能够验证IP是否可用，但是在使用的过程中发现，request（注意不是Request）时间很慢。request在程序里面设置的是通过代理ip访问网页，然后再本机读取代理ip的返回结果
	2.验证完成IP后，middleware正常使用。能够正常进入程序循环

新的问题：
	1.使用代理后，发现返回的request不正常，竟然是有道词典的界面。结合之前网络上查阅的说法是，此部分免费代理，是一个缓存服务器，现在请求的界面，可能是上一个别人的请求的缓存。